# PROCESAMIENTO Y CLASIFICACIÃ“N DE IMÃGENES CON EMNIST

## Autores
- [Carlos A. Cancino Escobar](https://github.com/C4ncino)
- [Juan Pablo GÃ³mez Haro Cabrera](https://github.com/JuanPabloGHC)

## IntroducciÃ³n

En este trabajo se describe la creaciÃ³n y entrenamiento de un modelo de red neuronal buscando y comparando la mejor arquitectura para esta, todos los modelos tiene la siguiente arquitectura base: 
  - Una capa de entrada con 784 neuronas para que cada una pues recibir un pixel de la imagen de 28x28, 
  - Una combinaciÃ³n de capas ocultas 
  - La capa de salida de 36 neuronas para ubicar la clase a la que pertenece que varÃ­an entre nÃºmeros y letras. 

Al finalizar del entrenamiento, se analizaron los resultados comparando entre las dos propuestas y las mÃ©tricas de precisiÃ³n para utilizar el modelo mejor entrenado. 

Posteriormente se buscarÃ¡ obtener imÃ¡genes de autos donde se visualicen placas de autos y al ejecutar el algoritmo se identifique cada carÃ¡cter de esta para mandarlo al modelo y predecir a que clase pertenece.

## Objetivo general

Entrenar un modelo que pueda identificar nÃºmeros y letras, sin importar la rotaciÃ³n, para poder identificar los valores de placas de autos a travÃ©s de imÃ¡genes.

## Objetivos especÃ­ficos

- Leer los datasets de entrenamientos y de pruebas para guardarlos dentro de nuestro programa.
- Encontrar la mejor soluciÃ³n de la arquitectura de la red neuronal para entrenar el modelo.
- Leer las imÃ¡genes de los vehÃ­culos.
- Obtener los caracteres de las placas.
- Probar el modelo con los caracteres obtenidos.

## TecnologÃ­as

- Python
- LibrerÃ­as:
  - Tensorflow
  - Opencv
  - Pandas
  - Numpy
  - Matplotlib.pyplot

Todas las librerÃ­as se pueden descargar mediante el archivo `requirements.txt`

## Dataset

El dataset que se utiliza es el de EMNIST dividido en 2 archivos .csv. El primero para entrenamiento y el segundo para pruebas, donde se encuentran las diferentes clases con la matriz de valores de 0 a 255 en escala de grises representando la escritura de las letras y nÃºmeros. Para su uso con los scripts se deben encontrar en la carpeta `data` bajo los nombres de `train.csv` y `test.csv`

Para el entrenamiento de los modelos se eliminaron aquellos valores que sean letras minÃºsculas (a, b, d, e, f, g, h, n, q, r, t) ya que al estar dirigido a reconocimiento de caracteres de Placas de coches, solo se requieren las letras mayÃºsculas, evitando mayor confusiÃ³n en el entrenamiento.

## Mapping

```python
classes = {
    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6',
    7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C',
    13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I',
    19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O',
    25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U',
    31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z'
}
```

## Modelos

Cada integrante entrenÃ³ un modelo diferente en busca de la mejor arquitectura. A continuaciÃ³n se muestran los resultados de cada uno de los modelos con el numero de Ã©pocas de entrenamiento y sus respectivas arquitecturas y sus resultados con el dataset de prueba. 

AsÃ­ mismo se muestran las grÃ¡ficas con los datos de la perdida de cada Ã©poca de entrenamiento la linea azul representa la perdida de la red durante el entrenamiento y la linea naranja la perdida de la red durante el pruebas.

### Historial de versiones Cancino

En este caso se realizaron las pruebas de 5 modelos diferentes, los cuales se muestran a continuaciÃ³n.

#### v1

**Epochs**: `15`

**Arquitectura**

| Tipo  | Unidades | ActivaciÃ³n | Dropout |
| :---: | :------: | :--------: | :-----: |
| Dense |   400    |    ReLu    |   0.3   |
| Dense |   250    |    ReLu    |   0.2   |
| Dense |   200    |    ReLu    |   0.2   |
| Dense |   100    |    ReLu    |   0.1   |
| Dense |   100    |    ReLu    |   N/A   |

**Resultados de la red**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.3448  |  87.68%   |
| Test  | 0.3321  |  88.73%   |


**GrÃ¡fica de desempeÃ±o**

![](./documentation/cancino/1.png)

---

#### v2

**Epochs**: `8`

**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   800    |         ReLU          |   0.2   |
| Dense |   800    |         ReLU          |   0.2   |
| Dense |   250    |         ReLU          |  0.15   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.2645  |  89.86%   |
| Test  | 0.3249  |  89.28%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/cancino/2.png)

---

#### v3

**Epochs**: `5`

**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   1000   |         ReLU          |   N/A   |
| Dense |   256    |         ReLU          |   0.3   |
| Dense |   128    |         ReLU          |   0.1   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.2985  |  88.94%   |
| Test  | 0.3496  |  87.74%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/cancino/3.png)

---

#### v4

**Epochs**: `15`


**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   190    |         ReLU          |   0.2   |
| Dense |   190    |         ReLU          |   0.2   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.2825  |  89.33%   |
| Test  | 0.3283  |  88.83%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/cancino/4.png)

---

#### v5

**Epochs**: `15`


**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   180    |         ReLU          |  0.15   |
| Dense |   180    |         ReLU          |  0.15   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.2922  |  88.86%   |
| Test  | 0.3352  |  88.65%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/cancino/5.png)

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/cancino/5.1.png)

### Historial de versiones Juan Pablo

#### v1

**Epochs**: `10`

**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   512    |         ReLU          |   0.2   |
| Dense |   256    |         ReLU          |   0.2   |
| Dense |   128    |         ReLU          |   0.1   |
| Dense |   256    |         ReLU          |   0.1   |
| Dense |    64    |         ReLU          |   N/A   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.3145  |  88.59%   |
| Test  | 0.3337  |  88.26%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/juanpablo/Graphic_v1.png)

---

#### v2

**Epochs**: `10`

**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   512    |         ReLU          |   0.2   |
| Dense |   256    |         ReLU          |   0.2   |
| Dense |   512    |         ReLU          |   0.2   |
| Dense |    64    |         ReLU          |   0.1   |
| Dense |    32    |         ReLU          |   N/A   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.3232  |  88.42%   |
| Test  | 0.3275  |  88.90%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/juanpablo/Graphic_v2.png)

---

#### v3

**Epochs**: `10`

**Arquitectura del Modelo**

| Capa  | Unidades | FunciÃ³n de ActivaciÃ³n | Dropout |
| :---: | :------: | :-------------------: | :-----: |
| Dense |   512    |         ReLU          |   0.2   |
| Dense |   256    |         ReLU          |  0.25   |
| Dense |   512    |         ReLU          |  0.25   |
| Dense |   128    |         ReLU          |   0.1   |
| Dense |    32    |         ReLU          |   N/A   |

**Resultados de la Red Neuronal**

| Etapa | PÃ©rdida | PrecisiÃ³n |
| :---: | :-----: | :-------: |
| Train | 0.3268  |  88.26%   |
| Test  | 0.3404  |  88.61%   |

**GrÃ¡fico de DesempeÃ±o**

![](./documentation/juanpablo/Graphic_v3.png)

## Pruebas

Se probaron dos formas distintas.

1. Se tomÃ³ cada carÃ¡cter en color blanco y el resto en color negro.
2. A esa primera forma se le hizo una rotaciÃ³n aleatoria entre 25 a 270 grados.

### Modelo Cancino v5.1

![Prueba1](./documentation/cancino/prueba1.png)
![Prueba2](./documentation/cancino/prueba2.png)
![Prueba3](./documentation/cancino/prueba3.png)

Modelo juanpablo v1

![Prueba1](./documentation/juanpablo/prueba1.png)
![Prueba2](./documentation/juanpablo/prueba2.png)


## Procesamiento de imagen

### Objetivo

Obtener los caracteres de una placa en una imagen de un vehÃ­culo en un formato de 28x28 en blanco y negro, siendo el carÃ¡cter en blanco y el fondo en negro, para poder mandarlo como una prueba al modelo.

### Procedimiento

- Se leen las imÃ¡genes con la librerÃ­a de opencv y con ayuda de la librerÃ­a de matplotlib se visualizan en una grÃ¡fica.
- Se tomaron las coordenadas manualmente de cada imagen, almacenando la informaciÃ³n en un json.
- Se crean recortes de cada carÃ¡cter con las coordenadas previamente almacenadas.
- De cada recorte se obtiene el valor mÃ¡ximo de su forma, en caso de ser una imagen rectangular, siendo el ancho o lo alto mÃ¡s alto, para crear un `canva` cuadrado de esa dimensiÃ³n.
- Se llena de blanco el `canva` y posteriormente se pega el recorte en el centro.
- Se recorre cada pÃ­xel de este nuevo `canva` y dependiendo el valor de pixel se le asigna un 0 o un 255 para quitar todo aquel color o tono que pueda distorsionar la imagen y al mismo tiempo invertir el blanco y negro.
- Se reajusta el tamaÃ±o de la imagen para tenerla en forma de 28x28.
- Se guarda la imagen con el nuevo tamaÃ±o y se hace una rotaciÃ³n aleatoria entre 25 a 270 grados y se guarda en la carpeta correspondiente.

### Ejemplos

**Imagen original**

![](./images/coche4.jpg)

**Caracteres**

![](./images/coche4/0.jpg)
![](./images/coche4/1.jpg)
![](./images/coche4/2.jpg)
![](./images/coche4/3.jpg)
![](./images/coche4/4.jpg)
![](./images/coche4/5.jpg)
![](./images/coche4/6.jpg)


![](./images/coche4/0_R.jpg)
![](./images/coche4/1_R.jpg)
![](./images/coche4/2_R.jpg)
![](./images/coche4/3_R.jpg)
![](./images/coche4/4_R.jpg)
![](./images/coche4/5_R.jpg)
![](./images/coche4/6_R.jpg)

### Json

```json
    {
        "path": "<directory/image.png>",
        "name": "<name>",
        "caracteres": [
            {
                "x": [
                    <x0>,
                    <x1>
                ],
                "y": [
                    <y0>,
                    <y1>
                ]
            },
            {
                "x": [
                    <x0>,
                    <x1>
                ],
                "y": [
                    <y0>,
                    <y1>
                ]
            },
            {
                "x": [
                    <x0>,
                    <x1>
                ],
                "y": [
                    <y0>,
                    <y1>
                ]
            }
        ]
    }
```

## Conclusiones

En cuanto al dataset el entrenamiento se ve afectado por la cantidad de clases que se generan, provocando mayor confusion al tomar en cuenta clases que no se utilizan, siendo ejemplo las letras minÃºsculas, ademas el hecho de que estÃ¡n rotadas, volteadas, etc, provoca que los patrones cambien y sea complicado la identificaciÃ³n de los caracteres puestosÂ correctamente.

Por otro lado, las arquitecturas podemos decir que las que se probaron con un mayor numero de neuronas en sus capas llegaron a un sobre-entrenamiento mÃ¡s rÃ¡pido que las demÃ¡s, no obstante uno de estos fue el que aparentemente mejor resultados obtuvo. Los demÃ¡s modelos que se construyeron tardaron mÃ¡s en entrenar y tuvieron una mejor relaciÃ³n entre su perdida de entrenamiento y la de validaciÃ³n.

Por Ãºltimo, la manera en que se le otorgan las imÃ¡genes de las placas es de suma importancia, ya que de esto depende que el modelo sea capaz de identificarlas. Por ejemplo importa que tan grande se vea el carÃ¡cter o la posible rotaciÃ³n que tenga.  


## Estructura

```plane
â”œâ”€â”€ğŸ“/documentation          
â”‚   â”œâ”€â”€ğŸ“/cancino         
â”‚   â”‚   â”œâ”€â”€ğŸ–¼ï¸[imÃ¡genes de grÃ¡ficas]
â”‚   â”‚   â””â”€â”€ğŸ–¼ï¸[imÃ¡genes de pruebas]
â”‚   â”œâ”€â”€ğŸ“/juanpablo       
â”‚   â”‚   â”œâ”€â”€ğŸ–¼ï¸[imÃ¡genes de grÃ¡ficas]
â”‚   â”‚   â””â”€â”€ğŸ–¼ï¸[imÃ¡genes de pruebas]
â”‚
â”œâ”€â”€ğŸ“/images                 
â”‚   â”œâ”€â”€ğŸ“/[carpeta de cada coche]
â”‚   â”‚   â””â”€â”€ğŸ–¼ï¸[imÃ¡genes de los caracteres]
â”‚   â””â”€â”€ğŸ–¼ï¸[fotos de coches]
â”‚
â”œâ”€â”€ğŸ“/models                 
â”‚   â”œâ”€â”€ğŸ“/cancino          
â”‚   â”‚   â””â”€â”€ğŸ“„[versiones de modelos de IA entrenados]
â”‚   â””â”€â”€ğŸ“/juanpablo        
â”‚       â””â”€â”€ğŸ“„[versiones de modelos de IA entrenados]
â”‚
â”œâ”€â”€ğŸclass_mapping.py
â”œâ”€â”€ğŸ“coches.json
â”œâ”€â”€ğŸE2_train_test_Cancino.py
â”œâ”€â”€ğŸE2.1_cars_Cancino.py
â”œâ”€â”€ğŸE2.2_generate images_Cancino.py
â”œâ”€â”€ğŸmodels.py
â””â”€â”€ğŸ“requirements.txt
```

- /documentation: 
    - ImÃ¡genes para documentar el proceso y resultados del entrenamientoy  las pruebas de cada integrante.
- /images: 
    - ImÃ¡genes originales de los coches y las imÃ¡genes de los caracteres obtenidos.
- /models: 
    - Modelos guardados por versiones previamente entrenados.
- class_mapping.py:
    - Diccionario de las clases resultantes del dataset.
- coches.json:
    - Json con la informaciÃ³n de las imÃ¡genes y sus coordenadas para obtener los caracteres.
- E2_train_test_Cancino.py:
    - CÃ³digo para entrenar y probar los dataset con el modelo indicado.
- E2.1_cars_Cancino.py:
    - CÃ³digo para hacer pruebas de cualquier modelo para una imagen especÃ­fica, visualizando las predicciones.
- E2.2_generate images_Cancino.py:
    - CÃ³digo para tomar cada imagen de coches y obtener los caracteres, de acuerdo con el json, haciendo el proceso adecuado a la imagen para que estÃ© en el formato adecuado para las pruebas y almacenandolas en carpetas separadas.
- requirements.txt:
    - Las dependencias que se utilizarÃ³n en el proyecto.

## InstalaciÃ³n

- Clonar el repositorio.
- Moverte a la carpeta del proyecto.
- Instalar todas las dependencias.

```bash
git clone https://github.com/C4ncino/Neuronal-Network-EMNIST.git

cd Neuronal-Network-EMNIST

pip install -r requirements.txt
```